(window.webpackJsonp=window.webpackJsonp||[]).push([[270],{626:function(e,s,t){"use strict";t.r(s);var a=t(42),r=Object(a.a)({},(function(){var e=this,s=e.$createElement,t=e._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"自定义-api-开发-爬虫调用情况统计"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#自定义-api-开发-爬虫调用情况统计"}},[e._v("#")]),e._v(" 自定义 API 开发 - 爬虫调用情况统计")]),e._v(" "),t("p",[e._v("前面动手编写了"),t("code",[e._v("CustomResource")]),e._v("，并且将其应用到原来的 HTML 视图类上。这一节我们来学习如何编写 API。")]),e._v(" "),t("p",[e._v("在之前对 API 的阅读中，我们知道 API 代码写在"),t("code",[e._v("scrapyd/webservice.py")]),e._v("中，为了保持风格一致，我们也将代码写在此文件中。")]),e._v(" "),t("h2",{attrs:{id:"编写自定义-api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#编写自定义-api"}},[e._v("#")]),e._v(" 编写自定义 API")]),e._v(" "),t("p",[e._v("在之前的 API 源码与视图类源码的阅读中，我们知道渲染由 render 方法完成，并且可以通过"),t("code",[e._v("render_GET")]),e._v("以及"),t("code",[e._v("render_POST")]),e._v("来指定请求方式。")]),e._v(" "),t("h3",{attrs:{id:"编写-get-类型的爬虫调用信息统计-api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#编写-get-类型的爬虫调用信息统计-api"}},[e._v("#")]),e._v(" 编写 GET 类型的爬虫调用信息统计 API")]),e._v(" "),t("ul",[t("li",[e._v("功能：爬虫调用情况")]),e._v(" "),t("li",[e._v("描述：如被调用过的爬虫、未被调用过的爬虫、被调用次数最多的爬虫名称及次数")])]),e._v(" "),t("p",[e._v("在"),t("code",[e._v("webservice.py")]),e._v("中新建类"),t("code",[e._v("ScheduleList")]),e._v("，它继承之前我们自己编写的视图类"),t("code",[e._v("CustomResource")]),e._v("：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("class ScheduleList(CustomResource):\n\n")])])]),t("p",[e._v("通过对其他 API 的调试，可以知道所有运行完毕的爬虫运行信息对象以列表的形式记录在"),t("code",[e._v("self.root.launcher.finished")]),e._v("中：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("[\n<scrapyd.launcher.ScrapyProcessProtocol object at 0x10cf97d68>,\n<scrapyd.launcher.ScrapyProcessProtocol object at 0x10cf546d8>,\n<scrapyd.launcher.ScrapyProcessProtocol object at 0x10cf3d4e0>\n]\n\n")])])]),t("p",[t("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16662fee3bc4f760?w=1536&h=1002&f=gif&s=4078380",alt:""}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/5/16643ab60543f5ff?w=686&h=264&f=png&s=69929",alt:"finished object"}})]),e._v(" "),t("p",[e._v("每个对象中包含对应爬虫相关运行信息，如项目名称 project、爬虫名称 spider、启动时间 start_time、结束时间 end_time、jobid、日志路径 logfile 等。")]),e._v(" "),t("p",[e._v("根据需求，要取的数据有：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("* 所有爬虫名称\n* 已运行完毕的爬虫名称\n* 爬虫调用记录\n\n")])])]),t("p",[e._v("通过 A 与 B 的差值计算得出未被调用过的爬虫、通过调用记录计算爬虫调用次数并取最大次数。")]),e._v(" "),t("p",[e._v("代码逻辑：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("* 取得运行完毕的爬虫运行记录列表\n* 获取爬虫列表\n* 计算差值，得出已被调用与未被调用的爬虫名列表\n* 计算爬虫调用记录中被调用次数最多的爬虫名及其次数\n* 将结果以原 JSON 风格渲染输出\n\n")])])]),t("p",[e._v("相应代码：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('class ScheduleList(CustomResource):\n    def render_GET(self, request):\n        """爬虫调用情况\n        如被调用过的爬虫、未被调用过的爬虫、被调用次数最多的爬虫名称及次数\n        """\n        finishes = self.root.launcher.finished\n        projects, spiders = get_ps(self)  # 项目/爬虫列表\n        invoked_spider, un_invoked_spider, most_record = get_invokes(finishes, spiders)  # 被调用过/未被调用的爬虫\n        return {"node_name": self.root.nodename, "status": "ok", "invoked_spider": list(invoked_spider),\n                "un_invoked_spider": list(un_invoked_spider), "most_record": most_record}\n\n')])])]),t("p",[e._v("其中通过"),t("code",[e._v("get_ps")]),e._v("方法获取爬虫列表：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('def get_ps(self):\n    """获取项目列表与爬虫列表\n    :param self:\n    :return: projects-项目列表， spiders-爬虫列表\n    """\n    projects = list(self.root.scheduler.list_projects())\n    spiders = get_spiders(projects)\n    return projects, spiders\n\n')])])]),t("p",[e._v("通过"),t("code",[e._v("get_invokes")]),e._v("方法计算所需结果：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('def get_invokes(finishes, spiders):\n        """获取已被调用与未被调用的爬虫名称及被调用次数最多的爬虫\n        :param: finishes 已运行完毕的爬虫运行信息记录列表\n        :param: spiders 所有爬虫名列表\n        :return: invoked-被调用过的爬虫集合, un_invoked-未被调用的爬虫集合, most_record-被调用次数最多的爬虫名与次数\n        """\n        invoked = set(i.spider for i in finishes)\n        un_invoked = set(spiders).difference(invoked)\n        invoked_record = Counter(i.spider for i in finishes)\n        most_record = invoked_record.most_common(1)[0] if invoked_record else ("nothing", 0)\n        return invoked, un_invoked, most_record\n\n')])])]),t("p",[e._v("还需要通过:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("def get_spiders(values):\n    if not values:\n        return []\n    # [['tips', 'nof'], ['nop']] -> ['tips', 'nof', 'nop']\n    value = list(reduce(lambda x, y: x+y,  map(get_spider_list, values)))  # first 2.8s\n    return value\n\n")])])]),t("h2",{attrs:{id:"自定义-api-的使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#自定义-api-的使用"}},[e._v("#")]),e._v(" 自定义 API 的使用")]),e._v(" "),t("h3",{attrs:{id:"配置路由"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#配置路由"}},[e._v("#")]),e._v(" 配置路由")]),e._v(" "),t("p",[e._v("代码编写好之后，还需要在为其配置路由映射规则。打开 Scrapyd 的配置文件"),t("code",[e._v("default_scrapyd.conf")]),e._v("，在"),t("code",[e._v("services")]),e._v("级下添加路由，如：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("[services]\nschedulelist.json = scrapyd.webservice.ScheduleList\n\n")])])]),t("p",[t("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/166630dc666d4c87?w=1074&h=424&f=gif&s=1562870",alt:""}})]),e._v(" "),t("p",[e._v("保存之后重新启动 Scrapyd 服务才能生效。")]),e._v(" "),t("h3",{attrs:{id:"api-的使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#api-的使用"}},[e._v("#")]),e._v(" API 的使用")]),e._v(" "),t("p",[e._v("由于编写代码时选择 "),t("code",[e._v("render_GET")]),e._v(" 方法，所以在使用时与原 API 使用方式一致，如果是使用 cURL 模拟请求，则请求语句为:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("curl: http://localhost:6800/schedulelist.json\n\n")])])]),t("p",[e._v("如果是使用 Postman 作为模拟请求工具，则：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/1666310ea7f2c5d0?w=1078&h=876&f=gif&s=786048",alt:""}})]),e._v(" "),t("p",[e._v("如果使用代码（requests）发起请求，代码为：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('import requests\n\nresp = requests.get("http://localhost:6800/schedulelist.json")\nprint(resp.text)\n\n')])])]),t("p",[e._v("发起请求后，得到的返回结果为：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('{\n"node_name": "node-name",\n"status": "ok",\n"invoked_spider": ["quinns","fabias"],\n"un_invoked_spider": ["artspider"],\n"most_record": ["fabias",3]\n    \n}\n\n')])])]),t("p",[e._v("返回结果中键的含义解释：")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("* node_name-请求发起者\n* status-请求状态，ok 为成功\n* invoked_spider-被调用过的爬虫列表\n* un_invoked_spider-未被调用过的爬虫列表\n* most_record-被调用次数最多的爬虫名及次数\n\n")])])]),t("h2",{attrs:{id:"小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[e._v("#")]),e._v(" 小结")]),e._v(" "),t("p",[e._v("基于之前几个小节学习的知识，结合需求分析，render 选型和逻辑分析，逐步完成了自定义 API 的编写。")])])}),[],!1,null,null,null);s.default=r.exports}}]);