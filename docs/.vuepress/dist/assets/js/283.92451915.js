(window.webpackJsonp=window.webpackJsonp||[]).push([[283],{641:function(t,a,e){"use strict";e.r(a);var s=e(42),r=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"通过-scrapyd-client-打包并部署爬虫"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#通过-scrapyd-client-打包并部署爬虫"}},[t._v("#")]),t._v(" 通过 Scrapyd-client 打包并部署爬虫")]),t._v(" "),e("p",[t._v("当爬虫代码编写完毕后，你可以选择直接运行启动文件来启动爬虫，也可以将爬虫部署到 Scrapyd 后，通过 Scrapyd 的 API 来启动爬虫。两种方法各自的优缺点以及应用场景会在后面的小节知识中讲解，这里我们先学会如何将爬虫项目打包并部署到 Scrapyd 上。")]),t._v(" "),e("p",[t._v("本小节将通过两个具体的部署例子（部署到本地以及部署到云服务器）以熟悉 Scrapy 爬虫项目打包、Scrapyd-client 的安装、使用以及爬虫项目部署过程。")]),t._v(" "),e("h2",{attrs:{id:"爬虫项目打包"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#爬虫项目打包"}},[t._v("#")]),t._v(" 爬虫项目打包")]),t._v(" "),e("p",[t._v("Scrapyd 打包部署的整个流程为：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/16/1667bf2808976988?w=507&h=763&f=png&s=29080",alt:""}})]),t._v(" "),e("h3",{attrs:{id:"打包前期"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#打包前期"}},[t._v("#")]),t._v(" 打包前期")]),t._v(" "),e("p",[t._v("当你使用 Scrapy 框架编写完爬虫代码之后，你需要将项目进行打包，才能够将其部署到 Scrapyd 上。"),e("a",{attrs:{href:"https://scrapyd.readthedocs.io/en/latest/deploy.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("官方文档"),e("OutboundLink")],1),t._v("对项目的打包有介绍：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("Deploying your project involves eggifying it and uploading the egg to Scrapyd via the\naddversion.json endpoint. You can do this manually, but the easiest way is to use the scrapyd-deploy tool provided by scrapyd-client which will do it all for you.\n\n")])])]),e("p",[t._v("Scrapy 项目需要使用 "),e("a",{attrs:{href:"https://github.com/scrapy/scrapyd-client",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scrapyd-client 工具"),e("OutboundLink")],1),t._v("进行打包。")]),t._v(" "),e("h3",{attrs:{id:"scrapyd-client"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#scrapyd-client"}},[t._v("#")]),t._v(" Scrapyd-client")]),t._v(" "),e("p",[t._v("它是 Scrapy 项目打包专用的客户端工具，同样是由 Scrapy 开发团队开发。使用 Scrapyd-client 将项目打包生成 "),e("code",[t._v(".egg")]),t._v(" 文件。")]),t._v(" "),e("h4",{attrs:{id:"scrapyd-client-的安装"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#scrapyd-client-的安装"}},[t._v("#")]),t._v(" Scrapyd-client 的安装")]),t._v(" "),e("p",[t._v("与 Scrapyd 一样，它也可以通过 pip 进行安装：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("pip install scrapyd-client\n\n")])])]),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16660bc9d4e89f1a?w=999&h=728&f=gif&s=895557",alt:"install scrapyd-client"}})]),t._v(" "),e("h4",{attrs:{id:"打包前的项目配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#打包前的项目配置"}},[t._v("#")]),t._v(" 打包前的项目配置")]),t._v(" "),e("p",[t._v("在打包前，我们需要对 Scrapy 项目进行设置。在 Scrapy 项目目录下，找到项目根目录的 "),e("code",[t._v(".cfg")]),t._v(" 文件（通常是 "),e("code",[t._v("scrapy.cfg")]),t._v("）并用编辑器打开：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("# Automatically created by: scrapy startproject\n#\n# For more information about the [deploy] section see:\n# https://scrapyd.readthedocs.io/en/latest/deploy.html\n\n[settings]\ndefault = arts.settings\n\n[deploy]\n#url = http://localhost:6800/\nproject = arts\n\n\n")])])]),e("p",[t._v("配置文件分为 Settings 级和 Deploy 级。Settings 中指定了项目所用的配置文件，而 Deploy 中指定项目打包的设置。")]),t._v(" "),e("ul",[e("li",[t._v("URL - 指定部署的目标地址")]),t._v(" "),e("li",[t._v("Project - 指定打包的项目")]),t._v(" "),e("li",[t._v("Deploy - 指定项目别名")])]),t._v(" "),e("p",[e("strong",[t._v("本小节，使用的项目为 "),e("code",[t._v("arts")]),t._v("，Scrapyd 服务为本地服务即 localhost:6800")]),t._v("，所以这里以此作为基础进行演示。")]),t._v(" "),e("p",[t._v("可以看到"),e("code",[t._v(".cfg")]),t._v("文件中 URL 处默认是有注释的，这里将注释去掉，并且为项目添加别名 "),e("code",[t._v("locals")]),t._v("：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("[settings]\ndefault = arts.settings\n\n[deploy:locals]\nurl = http://localhost:6800/\nproject = arts\n\n")])])]),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16660c2dbc020c0f?w=1242&h=773&f=gif&s=143494",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"打包部署"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#打包部署"}},[t._v("#")]),t._v(" 打包部署")]),t._v(" "),e("p",[t._v("而后在 arts 项目的根目录("),e("code",[t._v(".cfg")]),t._v("同级目录)下使用命令(此时必须保证 Scrapyd 服务是正常运行的)：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("scrapyd-deploy locals -p arts\n\n")])])]),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16660c7457ae67b3?w=1685&h=741&f=gif&s=213936",alt:""}})]),t._v(" "),e("p",[t._v("将项目打包并部署到指定的目标服务上，Scrapyd 服务会将请求结果以 json 格式返回：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v('node-name:arts$ scrapyd-deploy locals -p arts\nPacking version 1538645094\nDeploying to project "arts" in http://localhost:6800/addversion.json\nServer response (200):\n{"node_name": "node-name", "status": "ok", "project": "arts", "version": "1538645094", "spiders": 1}\n\n')])])]),e("p",[t._v("返回信息中包含了此次打包的版本号、目标服务地址、nodeName、项目状态、项目名称以及其中所包含的爬虫数量。并且在 Web 界面上也可以看到项目 arts 的名称，如下图所示：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16660c8c0229d20e?w=1308&h=501&f=gif&s=109488",alt:"html index"}})]),t._v(" "),e("h2",{attrs:{id:"思考题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#思考题"}},[t._v("#")]),t._v(" 思考题")]),t._v(" "),e("p",[e("code",[t._v("scrapy.cfg")]),t._v(" 文件中 Deploy 级设置里，Deploy 的名称是必须设置的吗？如果不设置会怎么样？可以有多个 Deploy 级配置吗？")]),t._v(" "),e("blockquote",[e("p",[t._v("我们可以通过动手实验，来验证这些问题。")])]),t._v(" "),e("p",[e("strong",[t._v("若 Deploy 不设置名称")])]),t._v(" "),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16660cedf6f041cd?w=1245&h=765&f=gif&s=119551",alt:"deploy"}})]),t._v(" "),e("p",[t._v("可以看到，Deploy 级配置不设置名称的话，在命令行中也无需使用名称，同样可以完成项目的打包。")]),t._v(" "),e("p",[e("strong",[t._v("若多个 Deploy 配置")])]),t._v(" "),e("p",[t._v("笔者在 192.168.0.61 服务器启动了 Scrapyd，并且在 "),e("code",[t._v("scrapy.cfg")]),t._v(" 文件中设置两组 Deploy 级别配置，其中一个 Deploy 不设置名称且 URL 指向本地 Scrapyd；另一个 Deploy 设置名称为 servers 且 URL 指向服务器的 Scrapyd。 "),e("code",[t._v("cfg")]),t._v(" 代码为：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("[settings]\ndefault = arts.settings\n\n[deploy]\nurl = http://localhost:6800/\nproject = arts\n\n[deploy:servers]\nurl = http://192.168.0.61:6800/\nproject = arts\n\n")])])]),e("p",[e("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2018/10/11/16660dcbf865f1cd?w=1242&h=764&f=gif&s=206864",alt:"deploy-servers"}})]),t._v(" "),e("p",[t._v("可以看到，多个 Deploy 级别的配置是允许的，并且我们可以使用 Deploy 的名称来区分它们。")]),t._v(" "),e("h2",{attrs:{id:"小结"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),e("p",[t._v("本小节通过 Scrapy 项目的部署案例，我们学会了 Scrapyd-client 的安装、使用以及打包前"),e("code",[t._v(".cfg")]),t._v("配置文件的相关配置，并且成功的将一个 Scrapy 项目打包部署到目标服务器上。")])])}),[],!1,null,null,null);a.default=r.exports}}]);