{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[284],{640:function(t,a,e){\"use strict\";e.r(a);var s=e(42),r=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[e(\"h1\",{attrs:{id:\"通过-scrapyd-client-打包并部署爬虫\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#通过-scrapyd-client-打包并部署爬虫\"}},[t._v(\"#\")]),t._v(\" 通过 Scrapyd-client 打包并部署爬虫\")]),t._v(\" \"),e(\"p\",[t._v(\"当爬虫代码编写完毕后，你可以选择直接运行启动文件来启动爬虫，也可以将爬虫部署到 Scrapyd 后，通过 Scrapyd 的 API 来启动爬虫。两种方法各自的优缺点以及应用场景会在后面的小节知识中讲解，这里我们先学会如何将爬虫项目打包并部署到 Scrapyd 上。\")]),t._v(\" \"),e(\"p\",[t._v(\"本小节将通过两个具体的部署例子（部署到本地以及部署到云服务器）以熟悉 Scrapy 爬虫项目打包、Scrapyd-client 的安装、使用以及爬虫项目部署过程。\")]),t._v(\" \"),e(\"h2\",{attrs:{id:\"爬虫项目打包\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#爬虫项目打包\"}},[t._v(\"#\")]),t._v(\" 爬虫项目打包\")]),t._v(\" \"),e(\"p\",[t._v(\"Scrapyd 打包部署的整个流程为：\")]),t._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/16/1667bf2808976988?w=507&h=763&f=png&s=29080\",alt:\"\"}})]),t._v(\" \"),e(\"h3\",{attrs:{id:\"打包前期\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#打包前期\"}},[t._v(\"#\")]),t._v(\" 打包前期\")]),t._v(\" \"),e(\"p\",[t._v(\"当你使用 Scrapy 框架编写完爬虫代码之后，你需要将项目进行打包，才能够将其部署到 Scrapyd 上。\"),e(\"a\",{attrs:{href:\"https://scrapyd.readthedocs.io/en/latest/deploy.html\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"官方文档\"),e(\"OutboundLink\")],1),t._v(\"对项目的打包有介绍：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v(\"Deploying your project involves eggifying it and uploading the egg to Scrapyd via the\\naddversion.json endpoint. You can do this manually, but the easiest way is to use the scrapyd-deploy tool provided by scrapyd-client which will do it all for you.\\n\\n\")])])]),e(\"p\",[t._v(\"Scrapy 项目需要使用 \"),e(\"a\",{attrs:{href:\"https://github.com/scrapy/scrapyd-client\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"Scrapyd-client 工具\"),e(\"OutboundLink\")],1),t._v(\"进行打包。\")]),t._v(\" \"),e(\"h3\",{attrs:{id:\"scrapyd-client\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scrapyd-client\"}},[t._v(\"#\")]),t._v(\" Scrapyd-client\")]),t._v(\" \"),e(\"p\",[t._v(\"它是 Scrapy 项目打包专用的客户端工具，同样是由 Scrapy 开发团队开发。使用 Scrapyd-client 将项目打包生成 \"),e(\"code\",[t._v(\".egg\")]),t._v(\" 文件。\")]),t._v(\" \"),e(\"h4\",{attrs:{id:\"scrapyd-client-的安装\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scrapyd-client-的安装\"}},[t._v(\"#\")]),t._v(\" Scrapyd-client 的安装\")]),t._v(\" \"),e(\"p\",[t._v(\"与 Scrapyd 一样，它也可以通过 pip 进行安装：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v(\"pip install scrapyd-client\\n\\n\")])])]),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16660bc9d4e89f1a?w=999&h=728&f=gif&s=895557\",alt:\"install scrapyd-client\"}})]),t._v(\" \"),e(\"h4\",{attrs:{id:\"打包前的项目配置\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#打包前的项目配置\"}},[t._v(\"#\")]),t._v(\" 打包前的项目配置\")]),t._v(\" \"),e(\"p\",[t._v(\"在打包前，我们需要对 Scrapy 项目进行设置。在 Scrapy 项目目录下，找到项目根目录的 \"),e(\"code\",[t._v(\".cfg\")]),t._v(\" 文件（通常是 \"),e(\"code\",[t._v(\"scrapy.cfg\")]),t._v(\"）并用编辑器打开：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v(\"# Automatically created by: scrapy startproject\\n#\\n# For more information about the [deploy] section see:\\n# https://scrapyd.readthedocs.io/en/latest/deploy.html\\n\\n[settings]\\ndefault = arts.settings\\n\\n[deploy]\\n#url = http://localhost:6800/\\nproject = arts\\n\\n\\n\")])])]),e(\"p\",[t._v(\"配置文件分为 Settings 级和 Deploy 级。Settings 中指定了项目所用的配置文件，而 Deploy 中指定项目打包的设置。\")]),t._v(\" \"),e(\"ul\",[e(\"li\",[t._v(\"URL - 指定部署的目标地址\")]),t._v(\" \"),e(\"li\",[t._v(\"Project - 指定打包的项目\")]),t._v(\" \"),e(\"li\",[t._v(\"Deploy - 指定项目别名\")])]),t._v(\" \"),e(\"p\",[e(\"strong\",[t._v(\"本小节，使用的项目为 \"),e(\"code\",[t._v(\"arts\")]),t._v(\"，Scrapyd 服务为本地服务即 localhost:6800\")]),t._v(\"，所以这里以此作为基础进行演示。\")]),t._v(\" \"),e(\"p\",[t._v(\"可以看到\"),e(\"code\",[t._v(\".cfg\")]),t._v(\"文件中 URL 处默认是有注释的，这里将注释去掉，并且为项目添加别名 \"),e(\"code\",[t._v(\"locals\")]),t._v(\"：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v(\"[settings]\\ndefault = arts.settings\\n\\n[deploy:locals]\\nurl = http://localhost:6800/\\nproject = arts\\n\\n\")])])]),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16660c2dbc020c0f?w=1242&h=773&f=gif&s=143494\",alt:\"\"}})]),t._v(\" \"),e(\"h4\",{attrs:{id:\"打包部署\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#打包部署\"}},[t._v(\"#\")]),t._v(\" 打包部署\")]),t._v(\" \"),e(\"p\",[t._v(\"而后在 arts 项目的根目录(\"),e(\"code\",[t._v(\".cfg\")]),t._v(\"同级目录)下使用命令(此时必须保证 Scrapyd 服务是正常运行的)：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v(\"scrapyd-deploy locals -p arts\\n\\n\")])])]),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16660c7457ae67b3?w=1685&h=741&f=gif&s=213936\",alt:\"\"}})]),t._v(\" \"),e(\"p\",[t._v(\"将项目打包并部署到指定的目标服务上，Scrapyd 服务会将请求结果以 json 格式返回：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v('node-name:arts$ scrapyd-deploy locals -p arts\\nPacking version 1538645094\\nDeploying to project \"arts\" in http://localhost:6800/addversion.json\\nServer response (200):\\n{\"node_name\": \"node-name\", \"status\": \"ok\", \"project\": \"arts\", \"version\": \"1538645094\", \"spiders\": 1}\\n\\n')])])]),e(\"p\",[t._v(\"返回信息中包含了此次打包的版本号、目标服务地址、nodeName、项目状态、项目名称以及其中所包含的爬虫数量。并且在 Web 界面上也可以看到项目 arts 的名称，如下图所示：\")]),t._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16660c8c0229d20e?w=1308&h=501&f=gif&s=109488\",alt:\"html index\"}})]),t._v(\" \"),e(\"h2\",{attrs:{id:\"思考题\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#思考题\"}},[t._v(\"#\")]),t._v(\" 思考题\")]),t._v(\" \"),e(\"p\",[e(\"code\",[t._v(\"scrapy.cfg\")]),t._v(\" 文件中 Deploy 级设置里，Deploy 的名称是必须设置的吗？如果不设置会怎么样？可以有多个 Deploy 级配置吗？\")]),t._v(\" \"),e(\"blockquote\",[e(\"p\",[t._v(\"我们可以通过动手实验，来验证这些问题。\")])]),t._v(\" \"),e(\"p\",[e(\"strong\",[t._v(\"若 Deploy 不设置名称\")])]),t._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16660cedf6f041cd?w=1245&h=765&f=gif&s=119551\",alt:\"deploy\"}})]),t._v(\" \"),e(\"p\",[t._v(\"可以看到，Deploy 级配置不设置名称的话，在命令行中也无需使用名称，同样可以完成项目的打包。\")]),t._v(\" \"),e(\"p\",[e(\"strong\",[t._v(\"若多个 Deploy 配置\")])]),t._v(\" \"),e(\"p\",[t._v(\"笔者在 192.168.0.61 服务器启动了 Scrapyd，并且在 \"),e(\"code\",[t._v(\"scrapy.cfg\")]),t._v(\" 文件中设置两组 Deploy 级别配置，其中一个 Deploy 不设置名称且 URL 指向本地 Scrapyd；另一个 Deploy 设置名称为 servers 且 URL 指向服务器的 Scrapyd。 \"),e(\"code\",[t._v(\"cfg\")]),t._v(\" 代码为：\")]),t._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[t._v(\"[settings]\\ndefault = arts.settings\\n\\n[deploy]\\nurl = http://localhost:6800/\\nproject = arts\\n\\n[deploy:servers]\\nurl = http://192.168.0.61:6800/\\nproject = arts\\n\\n\")])])]),e(\"p\",[e(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16660dcbf865f1cd?w=1242&h=764&f=gif&s=206864\",alt:\"deploy-servers\"}})]),t._v(\" \"),e(\"p\",[t._v(\"可以看到，多个 Deploy 级别的配置是允许的，并且我们可以使用 Deploy 的名称来区分它们。\")]),t._v(\" \"),e(\"h2\",{attrs:{id:\"小结\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#小结\"}},[t._v(\"#\")]),t._v(\" 小结\")]),t._v(\" \"),e(\"p\",[t._v(\"本小节通过 Scrapy 项目的部署案例，我们学会了 Scrapyd-client 的安装、使用以及打包前\"),e(\"code\",[t._v(\".cfg\")]),t._v(\"配置文件的相关配置，并且成功的将一个 Scrapy 项目打包部署到目标服务器上。\")])])}),[],!1,null,null,null);a.default=r.exports}}]);","extractedComments":[]}