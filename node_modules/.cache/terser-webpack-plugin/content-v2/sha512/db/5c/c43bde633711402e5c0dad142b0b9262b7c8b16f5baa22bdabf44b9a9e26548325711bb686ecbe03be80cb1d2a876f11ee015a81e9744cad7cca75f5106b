{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[287],{641:function(e,s,r){\"use strict\";r.r(s);var a=r(42),c=Object(a.a)({},(function(){var e=this,s=e.$createElement,r=e._self._c||s;return r(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[r(\"h1\",{attrs:{id:\"scrapyd-配置文件详解\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scrapyd-配置文件详解\"}},[e._v(\"#\")]),e._v(\" Scrapyd 配置文件详解\")]),e._v(\" \"),r(\"p\",[e._v(\"Scrapyd 的配置文件是非常重要的，配置文件中除了日志目录、日志数量、并发数等基础设置外还包括端口设置、IP 绑定设置、API 路由配置等应用层面的设置。\")]),e._v(\" \"),r(\"p\",[e._v(\"我们需要对 Scrapyd 的配置文件有清晰的认知，避免在认知模糊的情况下对其配置文件进行改动。而且在后续的小节中，也会介绍到如何在代码中读取配置文件以及对应的配置参数值。\")]),e._v(\" \"),r(\"h2\",{attrs:{id:\"配置文件参数详解\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#配置文件参数详解\"}},[e._v(\"#\")]),e._v(\" 配置文件参数详解\")]),e._v(\" \"),r(\"p\",[e._v(\"从之前的小节中我们可以看到，Scrapyd 会在几个核心类中读取 Scrapyd 的配置文件，获取相应的配置参数。那么，配置文件存放在哪里呢？\")]),e._v(\" \"),r(\"p\",[e._v(\"待你在 Python 环境下安装好 Scrapyd 后，它会在 Python 安装路径下的\"),r(\"code\",[e._v(\"site-packges\")]),e._v(\"目录下的\"),r(\"code\",[e._v(\"scrapyd\")]),e._v(\"目录内，配置文件名为\"),r(\"code\",[e._v(\"default_scrapyd.conf\")]),e._v(\"，其内容如下：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"[scrapyd]\\neggs_dir    = eggs\\nlogs_dir    = logs\\nitems_dir   =\\njobs_to_keep = 5\\ndbs_dir     = dbs\\nmax_proc    = 0\\nmax_proc_per_cpu = 4\\nfinished_to_keep = 100\\npoll_interval = 5.0\\nbind_address = 127.0.0.1\\nhttp_port   = 6800\\ndebug       = off\\nrunner      = scrapyd.runner\\napplication = scrapyd.app.application\\nlauncher    = scrapyd.launcher.Launcher\\nwebroot     = scrapyd.website.Root\\n\\n[services]\\nschedule.json     = scrapyd.webservice.Schedule\\ncancel.json       = scrapyd.webservice.Cancel\\naddversion.json   = scrapyd.webservice.AddVersion\\nlistprojects.json = scrapyd.webservice.ListProjects\\nlistversions.json = scrapyd.webservice.ListVersions\\nlistspiders.json  = scrapyd.webservice.ListSpiders\\ndelproject.json   = scrapyd.webservice.DeleteProject\\ndelversion.json   = scrapyd.webservice.DeleteVersion\\nlistjobs.json     = scrapyd.webservice.ListJobs\\ndaemonstatus.json = scrapyd.webservice.DaemonStatus\\n\\n\")])])]),r(\"p\",[e._v(\"它分为 \"),r(\"strong\",[e._v(\"Scrapyd\")]),e._v(\" 和 \"),r(\"strong\",[e._v(\"Services\")]),e._v(\" 两种级别，其中每个参数的作用，在 \"),r(\"a\",{attrs:{href:\"https://scrapyd.readthedocs.io/en/stable/config.html\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Scrapyd 官方文档\"),r(\"OutboundLink\")],1),e._v(\"中有详细的介绍。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"scrapyd-级配置\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scrapyd-级配置\"}},[e._v(\"#\")]),e._v(\" Scrapyd 级配置\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"其中\"),r(\"code\",[e._v(\".._dir\")]),e._v(\"均为对应的目录设置，如\"),r(\"code\",[e._v(\"eggs_dir、logs_dir、items_dir、dbs_dir\")]),e._v(\"。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"jobs_to_keep\")]),e._v(\" - 保存每个爬虫的日志记录数，默认为 5，你可以设置为 500。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"max_proc\")]),e._v(\" - Scrapyd 最大并发数，默认 0 时使用\"),r(\"code\",[e._v(\"max_proc_per_cpu\")]),e._v(\"设置的数量。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"max_proc_per_cpu\")]),e._v(\" - 每个 CPU 最大并发数设置，默认为 4.\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"finished_to_keep\")]),e._v(\" - 在 launcher 中保持的进程数，默认 100.\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"poll_interval\")]),e._v(\" - 轮询队列的间隔，默认 5秒，可以设置 0.2 或其它 int/float 数值。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"bind_address\")]),e._v(\" - 默认值 127.0.0.1，只允许本机访问，如果想要开启远程访问改为 0.0.0.0 即可。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"http_port\")]),e._v(\" - http 端口，默认 6800。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"debug\")]),e._v(\" - Debug 调试开关。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"runner、application、launcher、webroot\")]),e._v(\" - 关联的是 Scrapyd 项目代码中编写的对应对象。\")])]),e._v(\" \"),r(\"blockquote\",[r(\"p\",[e._v(\"以上配置只能写在 Scrapyd 级配置中，如果写错了或者写到其他位置，Scrapyd 在读取配置文件的时候是读取不到的。\")])]),e._v(\" \"),r(\"h3\",{attrs:{id:\"services-级配置\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#services-级配置\"}},[e._v(\"#\")]),e._v(\" Services 级配置\")]),e._v(\" \"),r(\"p\",[e._v(\"Services 级专用于配置 API 的路由映射关系，将 URL 地址与资源关联起来。\")]),e._v(\" \"),r(\"p\",[e._v(\"假如在 \"),r(\"code\",[e._v(\"webservice.py\")]),e._v(\" 中新增一个名为 Caps 的类，那么在配置文件中的写法应与其他类的路由写法一致：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"[services]\\nschedule.json     = scrapyd.webservice.Schedule\\n... ...\\ndaemonstatus.json = scrapyd.webservice.DaemonStatus\\ncaps.json = scrapyd.webservice.Caps\\n\\n\")])])]),r(\"blockquote\",[r(\"p\",[e._v(\"下面这张 GIF 动图演示了整个 API 代码编写、路由配置以及 API 使用的过程。\")])]),e._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/166613776ef306c2?w=1363&h=862&f=gif&s=4961299\",alt:\"\"}})]),e._v(\" \"),r(\"h2\",{attrs:{id:\"小结\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#小结\"}},[e._v(\"#\")]),e._v(\" 小结\")]),e._v(\" \"),r(\"p\",[e._v(\"本小节我们学习了 Scrapyd 配置文件中各个参数的作用以及配置文件级别的区别，并且通过编写 API 的案例对 Scrapyd 配置文件进行了设置。有了实践经验后，我们就可以在后面的小节中对 Scrapyd 的配置文件进行自定义设置了。\")])])}),[],!1,null,null,null);s.default=c.exports}}]);","extractedComments":[]}