{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[268],{627:function(e,t,r){\"use strict\";r.r(t);var a=r(42),s=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[r(\"h1\",{attrs:{id:\"动手调试-scrapyd-代码\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#动手调试-scrapyd-代码\"}},[e._v(\"#\")]),e._v(\" 动手调试 Scrapyd 代码\")]),e._v(\" \"),r(\"p\",[e._v(\"通过前面几个小节的学习，我们了解了 Scrapyd 的基础知识、Scrapyd 的使用、 \"),r(\"a\",{attrs:{href:\"https://juejin.im/book/5bb5d3fa6fb9a05d2a1d819a/section/5bb5ed2ff265da0aa06f08ac\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Scrapyd 源码目录\"),r(\"OutboundLink\")],1),e._v(\"及\"),r(\"a\",{attrs:{href:\"https://juejin.im/book/5bb5d3fa6fb9a05d2a1d819a/section/5bb7206f5188255c3f6beeb7\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"视图类\"),r(\"OutboundLink\")],1),e._v(\"，逐步深入的领略了 Scrapyd 整个结构和编码风格。但是：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"1、如何才能够更深入的了解它的运行流程呢？\\n2、爬虫的运行记录会存放在哪里呢？\\n3、在原有的 Scrapyd 代码中，有哪些可以为我所用？\\n4、它的 API 由哪些元素构成？\\n5、我们可以改动现有函数或方法吗？\\n6、... ...\\n\\n\")])])]),r(\"p\",[e._v(\"对于以上列出的问题，我们不得而知，但又不得不知。\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"* 不得而知：因为之前的小节内容中，并未深入讲解 Scrapyd 的源码，仅停留在使用与结构上；\\n* 不得不知：对于一个框架的学习，必须深入到代码中，通过对代码的调试才能够在脑海中绘制出框架的图谱；\\n\\n\")])])]),r(\"p\",[e._v(\"所以，在这里我将会用代码调试的方式，跟大家一起深入的了解 Scrapyd，看一看爬虫运行记录存放位置，筛选可以为我所用的 Scrapyd 代码。拆解它的 API，看一看 API 由哪些元素构成，试一试能不能改动现有函数。\")]),e._v(\" \"),r(\"p\",[e._v(\"只有这样，我们才能够在脑海中绘制出清晰的 Scrayd 图谱，为我们自己能够编写出与 Scrapyd 风格一致的代码夯实基础。\")]),e._v(\" \"),r(\"blockquote\",[r(\"p\",[e._v(\"为什么要风格一致？\")])]),e._v(\" \"),r(\"p\",[e._v(\"在框架代码的改动过程中，应尽量与原框架代码保持一致的风格，有助于后期代码管理和维护，同时也能够减少一些不易察觉的错误。\")]),e._v(\" \"),r(\"h2\",{attrs:{id:\"scrapyd-的代码调试\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scrapyd-的代码调试\"}},[e._v(\"#\")]),e._v(\" Scrapyd 的代码调试\")]),e._v(\" \"),r(\"p\",[e._v(\"在调试之前，我们想一想：选择哪一部分的代码进行调试会比较好呢？\")]),e._v(\" \"),r(\"p\",[e._v(\"根据之前小节对 Scrapyd 源码目录结构以及常用功能的学习，我认为选择启动文件、首页以及 API 中的\"),r(\"code\",[e._v(\"listspiders.json\")]),e._v(\"进行调试，能够让我们在短时间内对 Scrapyd 有更深一层的理解。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"启动文件代码调试\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#启动文件代码调试\"}},[e._v(\"#\")]),e._v(\" 启动文件代码调试\")]),e._v(\" \"),r(\"h4\",{attrs:{id:\"scrapyd-run-py\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scrapyd-run-py\"}},[e._v(\"#\")]),e._v(\" scrapyd_run.py\")]),e._v(\" \"),r(\"p\",[e._v(\"启动文件位于\"),r(\"code\",[e._v(\"scrapyd/scripts\")]),e._v(\"目录下，名为\"),r(\"code\",[e._v(\"scrapyd_run.py\")]),e._v(\"，文件中代码不多：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"#!/usr/bin/env python\\n\\nfrom twisted.scripts.twistd import run\\nfrom os.path import join, dirname\\nfrom sys import argv\\nimport scrapyd\\n\\n\\ndef main():\\n    argv[1:1] = ['-n', '-y', join(dirname(scrapyd.__file__), 'txapp.py')]\\n    run()\\n\\nif __name__ == '__main__':\\n    main()\\n\\n\")])])]),r(\"h4\",{attrs:{id:\"import-代码释义\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#import-代码释义\"}},[e._v(\"#\")]),e._v(\" Import 代码释义\")]),e._v(\" \"),r(\"p\",[e._v(\"Python 的代码自上而下执行，那就让我们从 Imoprt 开始：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"from twisted.scripts.twistd import run   \\nfrom os.path import join, dirname\\nfrom sys import argv\\nimport scrapyd\\n\\n\")])])]),r(\"p\",[e._v(\"导入这些包的作用是什么呢？\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"# 先从 Scrapyd 的底层框架 Twisted 中导入用于启动 Twisted 的 Run 方法\\n# 然后从 os.path 中导入用于操作文件路径的 join 和 dirname 方法\\n# 再从 sys 中导入获取命令行参数的 argv 方法\\n# 最后导入 Scrapyd 项目本身\\n\\n\")])])]),r(\"h4\",{attrs:{id:\"main-函数与-argv\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#main-函数与-argv\"}},[e._v(\"#\")]),e._v(\" main 函数与 argv\")]),e._v(\" \"),r(\"p\",[e._v(\"接着定义了\"),r(\"code\",[e._v(\"main\")]),e._v(\"函数：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"def main():\\n    argv[1:1] = ['-n', '-y', join(dirname(scrapyd.__file__), 'txapp.py')]\\n    run()\\n\\n\")])])]),r(\"p\",[e._v(\"函数中的 argv 与其他参数到底有什么作用呢？我们可以通过 PyCharm 在 run() 打断点，让其运行到 run() 时暂停，这样我们就可以观察 argv 了，如下图所示：\")]),e._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16662d856b8acc24?w=1538&h=998&f=gif&s=2808159\",alt:\"\"}})]),e._v(\" \"),r(\"p\",[e._v(\"Debug 后得到 argv 的值为：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\" ['/Volumes/HFSFILE/github/scrapyd/scrapyd/scripts/scrapyd_run.py', '-n', '-y', '/Volumes/HFSFILE/github/scrapyd/scrapyd/txapp.py']\\n\\n\")])])]),r(\"p\",[e._v(\"它是一个列表，列表的第一个元素是 \"),r(\"code\",[e._v(\"scrapyd_run.py\")]),e._v(\" 的文件路径，也就是\"),r(\"code\",[e._v(\"argv\")]),e._v(\"代码所获得的路径值，argv 会默认将当前文件路径添加到列表的第一个元素；列表最后一个元素是文件 \"),r(\"code\",[e._v(\"txapp.py\")]),e._v(\" 的路径，也就是\"),r(\"code\",[e._v(\"join(dirname(scrapyd.__file__), 'txapp.py')\")]),e._v(\"这部分代码获取到的值。那么，\"),r(\"code\",[e._v(\"-n\")]),e._v(\"和\"),r(\"code\",[e._v(\"-y\")]),e._v(\"到底是什么呢？\")]),e._v(\" \"),r(\"p\",[e._v(\"为了更好的观察，这里将 argv 这一整行代码注释掉：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"def main():\\n    # argv[1:1] = ['-n', '-y', join(dirname(scrapyd.__file__), 'txapp.py')]\\n    run()\\n\\n\")])])]),r(\"p\",[e._v(\"然后直接运行\"),r(\"code\",[e._v(\"scrapyd_run.py\")]),e._v(\"文件。\")]),e._v(\" \"),r(\"p\",[e._v(\"发现运行失败，并在 PyCharm 的运行记录框中给出了提示，如下图：\")]),e._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16662dba20cf559c?w=1540&h=1002&f=gif&s=3478686\",alt:\"\"}})]),e._v(\" \"),r(\"p\",[e._v(\"提示中出现了\"),r(\"code\",[e._v(\"-n\")]),e._v(\"和\"),r(\"code\",[e._v(\"-y\")]),e._v(\"参数，它们的含义是什么？\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"-n, --nodaemon don't daemonize, don't use default umask of 0077\\n-y, --python=  read an application from within a Python file (implies -o)\\n\\n\")])])]),r(\"ul\",[r(\"li\",[e._v(\"-n 代表不以守护进程模式启动\")]),e._v(\" \"),r(\"li\",[e._v(\"-y 代表从 Python 文件中读取应用程序\")])]),e._v(\" \"),r(\"p\",[e._v(\"回头再来看看 argv 的作用，\"),r(\"a\",{attrs:{href:\"https://docs.python.org/3.6/library/sys.html?highlight=argv#sys.argv\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Python 文档中对 argv 的介绍\"),r(\"OutboundLink\")],1),e._v(\"如下：\")]),e._v(\" \"),r(\"blockquote\",[r(\"p\",[e._v(\"sys.argv\")]),e._v(\" \"),r(\"p\",[r(\"code\",[e._v(\"The list of command line arguments passed to a Python script. argv[0] is the script name\")]),e._v(\" (it is operating system dependent whether this is a full pathname or not). If the command was executed using the -c command line option to the interpreter, argv[0] is set to the string '-c'. If no script name was passed to the Python interpreter, argv[0] is the empty string.\")])]),e._v(\" \"),r(\"p\",[e._v(\"其中我对释义做了高亮，那段释义翻译成中文：\")]),e._v(\" \"),r(\"blockquote\",[r(\"p\",[e._v(\"传递给 Python script 的命令行参数列表，argv[0] 是 script 文件名\")])]),e._v(\" \"),r(\"p\",[e._v(\"这也解释了，为什么 argv[1:1] 列表的第一个元素是 scrapyd_run.py 的路径，其余的释义并不重要，在这里可以将其略过。\")]),e._v(\" \"),r(\"h4\",{attrs:{id:\"txapp\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#txapp\"}},[e._v(\"#\")]),e._v(\" txapp\")]),e._v(\" \"),r(\"p\",[e._v(\"那么，传递进来的 txapp.py 文件，又是做什么的呢？这是它的代码：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"# this file is used to start scrapyd with twistd -y\\nfrom scrapyd import get_application\\napplication = get_application()\\n\\n\")])])]),r(\"p\",[e._v(\"它从 Scrapyd 项目中导入\"),r(\"code\",[e._v(\"get_application\")]),e._v(\"方法，通过\"),r(\"code\",[e._v(\"Ctrl/Commond+鼠标左键\")]),e._v(\" 跟进\"),r(\"code\",[e._v(\"get_application\")]),e._v(\"方法的代码：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"from scrapy.utils.misc import load_object\\nfrom scrapyd.config import Config\\n\\n\\ndef get_application(config=None):\\n    if config is None:\\n        config = Config()\\n    apppath = config.get('application', 'scrapyd.app.application')\\n    appfunc = load_object(apppath)\\n    return appfunc(config)\\n\\n\")])])]),r(\"p\",[e._v(\"它的逻辑很简单：\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"判断是否传入指定的 config。 如果有则使用指定的 config，如无则使用框架预先定义的\"),r(\"code\",[e._v(\"Config\")])]),e._v(\" \"),r(\"li\",[e._v(\"初始化\"),r(\"code\",[e._v(\"Config\")]),e._v(\"并使用\"),r(\"code\",[e._v(\"get()与_getany()\")]),e._v(\"，最终获得传入的字符串\"),r(\"code\",[e._v(\"'scrapyd.app.application'\")])]),e._v(\" \"),r(\"li\",[e._v(\"使用 \"),r(\"code\",[e._v(\"appfunc = load_object(apppath)\")]),e._v(\"获得 mod 对象的 application 属性对象\")]),e._v(\" \"),r(\"li\",[e._v(\"最后使用 \"),r(\"code\",[e._v(\"appfunc(config)\")]),e._v(\" 将得到的\"),r(\"code\",[e._v(\"Componentized\")]),e._v(\"对象返回给\"),r(\"code\",[e._v(\"txapp\")]),e._v(\"中的\"),r(\"code\",[e._v(\"application\")]),e._v(\" 变量\")])]),e._v(\" \"),r(\"blockquote\",[r(\"p\",[e._v(\"至此，整个 Scrapyd 服务的启动就完成了。\")])]),e._v(\" \"),r(\"p\",[e._v(\"或许你还有疑问，为什么要返回\"),r(\"code\",[e._v(\"Componentized\")]),e._v(\"对象给\"),r(\"code\",[e._v(\"application\")]),e._v(\"变量呢?\"),r(\"code\",[e._v(\"run()\")]),e._v(\"方法执行了什么呢？\")]),e._v(\" \"),r(\"p\",[e._v(\"这里我们学习的是 Scrapyd，能够大致理解整个流程即可，对于十分细致的 Twisted 方法及函数还需翻阅 Twisted 文档。通过上面的代码跟进及调试，我们基本可以理清它们的顺序和关系：\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"在启动之前，通过\"),r(\"code\",[e._v(\"scrapyd_run.py\")]),e._v(\"的\"),r(\"code\",[e._v(\"argv\")]),e._v(\"设置了基本参数：\"),r(\"code\",[e._v(\"-n\")]),e._v(\"和\"),r(\"code\",[e._v(\"-y\")]),e._v(\"参数。并且将\"),r(\"code\",[e._v(\"txapp\")]),e._v(\"的\"),r(\"code\",[e._v(\"application\")]),e._v(\"对象以参数的形式与\"),r(\"code\",[e._v(\"-n\")]),e._v(\"和\"),r(\"code\",[e._v(\"-y\")]),e._v(\"一并传递给了\"),r(\"code\",[e._v(\"twisted\")]),e._v(\"(application 是固定的参数名)。\")]),e._v(\" \"),r(\"li\",[r(\"code\",[e._v(\"run()\")]),e._v(\"方法是以\"),r(\"code\",[e._v(\"argv\")]),e._v(\"传递对应的参数作为启动配置的，\"),r(\"code\",[e._v(\"run()\")]),e._v(\"执行时，就启动了整个项目。\")])]),e._v(\" \"),r(\"p\",[e._v(\"所以，整个 Scrapyd 服务由\"),r(\"code\",[e._v(\"run()\")]),e._v(\"方法唤起，但是唤起前将\"),r(\"code\",[e._v(\"txapp.py\")]),e._v(\"所获得的\"),r(\"code\",[e._v(\"Componentized\")]),e._v(\"对象以及\"),r(\"code\",[e._v(\"-n\")]),e._v(\"和\"),r(\"code\",[e._v(\"-y\")]),e._v(\"参数传递给\"),r(\"code\",[e._v(\"twisted\")]),e._v(\"。\")]),e._v(\" \"),r(\"h2\",{attrs:{id:\"首页代码调试\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#首页代码调试\"}},[e._v(\"#\")]),e._v(\" 首页代码调试\")]),e._v(\" \"),r(\"p\",[e._v(\"首页相关的代码在\"),r(\"code\",[e._v(\"website.py\")]),e._v(\"中的\"),r(\"code\",[e._v(\"Home\")]),e._v(\"类中,其代码如下：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v('\\nclass Home(resource.Resource):\\n\\n    def __init__(self, root, local_items):\\n        resource.Resource.__init__(self)\\n        self.root = root\\n        self.local_items = local_items\\n\\n    def render_GET(self, txrequest):\\n        vars = {\\n            \\'projects\\': \\', \\'.join(self.root.scheduler.list_projects())\\n        }\\n        s = \"\"\"\\n            <html>\\n            <head><title>Scrapyd</title></head>\\n            <body>\\n            <h1>Scrapyd</h1>\\n            <p>Available projects: <b>%(projects)s</b></p>\\n            <ul>\\n            <li><a href=\"/jobs\">Jobs</a></li>\\n            \"\"\" % vars\\n                    if self.local_items:\\n                        s += \\'<li><a href=\"/items/\">Items</a></li>\\'\\n                    s += \"\"\"\\n            <li><a href=\"/logs/\">Logs</a></li>\\n            <li><a href=\"http://scrapyd.readthedocs.org/en/latest/\">Documentation</a></li>\\n            </ul>\\n            \\n            <h2>How to schedule a spider?</h2>\\n            \\n            <p>To schedule a spider you need to use the API (this web UI is only for\\n            monitoring)</p>\\n            \\n            <p>Example using <a href=\"http://curl.haxx.se/\">curl</a>:</p>\\n            <p><code>curl http://localhost:6800/schedule.json -d project=default -d spider=somespider</code></p>\\n            \\n            <p>For more information about the API, see the <a href=\"http://scrapyd.readthedocs.org/en/latest/\">Scrapyd documentation</a></p>\\n            </body>\\n            </html>\\n        \"\"\" % vars\\n        return s.encode(\\'utf-8\\')\\n\\n')])])]),r(\"p\",[e._v(\"在 Web 页面中界面如下图所示：\")]),e._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/9/16657440a52d28a5?w=805&h=341&f=png&s=29993\",alt:\"web index\"}})]),e._v(\" \"),r(\"h3\",{attrs:{id:\"render-get\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#render-get\"}},[e._v(\"#\")]),e._v(\" render_GET\")]),e._v(\" \"),r(\"p\",[e._v(\"通过 Web 页面与 Home 类中的代码对比，不难发现数据的渲染都是在\"),r(\"code\",[e._v(\"render_GET\")]),e._v(\"方法中，\"),r(\"code\",[e._v(\"render_GET\")]),e._v(\"由以下三个部分组成：\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"vars - 爬虫项目列表\")]),e._v(\" \"),r(\"li\",[e._v(\"s - 嵌入爬虫项目列表 vars 的 html 文本\")]),e._v(\" \"),r(\"li\",[e._v(\"return - 将文本数据编码后返回给 render 方法，最后呈现到页面\")])]),e._v(\" \"),r(\"p\",[e._v(\"那\"),r(\"code\",[e._v(\"render_GET\")]),e._v(\"与\"),r(\"code\",[e._v(\"render\")]),e._v(\"有什么关系？为什么它通过\"),r(\"code\",[e._v(\"return\")]),e._v(\"就能够将页面呈现出来？这部分在 \"),r(\"a\",{attrs:{href:\"https://juejin.im/book/5bb5d3fa6fb9a05d2a1d819a/section/5bb7206f5188255c3f6beeb7\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Scrapyd 视图类\"),r(\"OutboundLink\")],1),e._v(\"已经做了讲解，这里就不再多提。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"爬虫项目的数据来源\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#爬虫项目的数据来源\"}},[e._v(\"#\")]),e._v(\" 爬虫项目的数据来源\")]),e._v(\" \"),r(\"p\",[e._v(\"上面提到，\"),r(\"code\",[e._v(\"vars\")]),e._v(\"负责将爬虫项目列表取出，这部分的代码是：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"vars = {'projects': ', '.join(self.root.scheduler.list_projects())}\\n\\n\")])])]),r(\"p\",[e._v(\"真正负责取数据的是\"),r(\"code\",[e._v(\"self.root.scheduler.list_projects()\")]),e._v(\",我们将代码拆成\"),r(\"code\",[e._v(\"self.root.scheduler\")]),e._v(\"与\"),r(\"code\",[e._v(\"self.root.scheduler.list_projects()\")]),e._v(\"并对其进行调试，看看这段代码包含了哪些数据信息，先将 Home 中 \"),r(\"code\",[e._v(\"render_GET\")]),e._v(\" 的代码改成（省略号代表下面的代码保持不变，此处省略）：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"    def render_GET(self, txrequest):\\n        scheduler = self.root.scheduler\\n        pro = scheduler.list_projects()\\n        vars = {\\n            'projects': ', '.join(self.root.scheduler.list_projects())\\n        }\\n        ... ...\\n\\n\")])])]),r(\"p\",[e._v(\"新增加了\"),r(\"code\",[e._v(\"scheduler\")]),e._v(\"和\"),r(\"code\",[e._v(\"pro\")]),e._v(\"，并在变量 \"),r(\"code\",[e._v(\"vars\")]),e._v(\"处打断点，然后通过 PyCharm 的\"),r(\"code\",[e._v(\"debug\")]),e._v(\"按钮运行\"),r(\"code\",[e._v(\"scrapyd_run.py\")]),e._v(\"文件。待 Scrapyd 服务运行起来后，在浏览器访问\"),r(\"code\",[e._v(\"localhost:6800\")]),e._v(\"，程序运行后就会暂停在断点 vars 处，如下图所示：\")]),e._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/9/166575b9887eb330?w=1214&h=720&f=png&s=234005\",alt:\"\"}})]),e._v(\" \"),r(\"h3\",{attrs:{id:\"encode\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#encode\"}},[e._v(\"#\")]),e._v(\" Encode\")]),e._v(\" \"),r(\"p\",[e._v(\"在最后\"),r(\"code\",[e._v(\"return\")]),e._v(\"的时候，需要对\"),r(\"code\",[e._v(\"html\")]),e._v(\"文本进行编码转化,将原本的\"),r(\"code\",[e._v(\"str\")]),e._v(\"转成\"),r(\"code\",[e._v(\"bytes\")]),e._v(\"格式数据，也就是：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"return s.encode('utf-8')\\n\\n\")])])]),r(\"p\",[e._v(\"如果直接将 \"),r(\"code\",[e._v(\"str\")]),e._v(\" 返回的话，会得到\"),r(\"code\",[e._v(\"Request did not return bytes\")]),e._v(\"的错误提示。\")]),e._v(\" \"),r(\"h2\",{attrs:{id:\"api-代码调试\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#api-代码调试\"}},[e._v(\"#\")]),e._v(\" API 代码调试\")]),e._v(\" \"),r(\"p\",[e._v(\"API 作为 Scrapyd 使用最广泛并且最灵活的部分，是 Scrapyd 的功能担当。假如没有这些 API，对于 Scrapyd 的使用者来说，在爬虫项目管理方面将变得困难。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"listspiders-json\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#listspiders-json\"}},[e._v(\"#\")]),e._v(\" listspiders.json\")]),e._v(\" \"),r(\"p\",[e._v(\"Scrapyd 所有 API 对应的类都在 \"),r(\"code\",[e._v(\"webservice.py\")]),e._v(\" 文件中，本次将 \"),r(\"code\",[e._v(\"listspiders.json\")]),e._v(\" 作为调试的案例，其代码为：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v('class ListSpiders(WsResource):\\n    def render_GET(self, txrequest):\\n        args = native_stringify_dict(copy(txrequest.args), keys_only=False)\\n        project = args[\\'project\\'][0]\\n        version = args.get(\\'_version\\', [\\'\\'])[0]\\n        spiders = get_spider_list(project, runner=self.root.runner, version=version)\\n        return {\"node_name\": self.root.nodename, \"status\": \"ok\", \"spiders\": spiders}\\n\\n')])])]),r(\"p\",[e._v(\"我们来大致分析一下，这个类自上而下做了什么：\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"首先，这个类继承自 WsResource\")]),e._v(\" \"),r(\"li\",[e._v(\"其次，它同样是使用了 \"),r(\"code\",[e._v(\"render_GET\")]),e._v(\" 来渲染数据\")]),e._v(\" \"),r(\"li\",[e._v(\"通过 \"),r(\"code\",[e._v(\"native_stringify_dict\")]),e._v(\" 方法获取请求时携带的参数\")]),e._v(\" \"),r(\"li\",[e._v(\"根据传递的爬虫项目名称获取 project 对象以及版本 Version\")]),e._v(\" \"),r(\"li\",[e._v(\"通过 \"),r(\"code\",[e._v(\"get_spider_list\")]),e._v(\" 方法以及对应参数获取爬虫名称列表\")]),e._v(\" \"),r(\"li\",[e._v(\"最后将爬虫列表结果以 json 格式返回\")])]),e._v(\" \"),r(\"p\",[e._v(\"从逻辑上可以看到，关键的地方就在于\"),r(\"code\",[e._v(\"args = native_stringify_dict(copy(txrequest.args), keys_only=False)\")]),e._v(\"，需要在使用时传递指定的爬虫项目名称。\")]),e._v(\" \"),r(\"p\",[e._v(\"如果不传递任何参数，则返回错误提示: \"),r(\"code\",[e._v('{\"node_name\": \"GannicusdeiMac\", \"status\": \"error\", \"message\": \"\\'project\\'\"}')])]),e._v(\" \"),r(\"p\",[e._v(\"如果传递了错误的参数名或者不存在的项目名称，同样会得到错误提示。所以在 \"),r(\"a\",{attrs:{href:\"https://scrapyd.readthedocs.io/en/stable/api.html#listspiders-json\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Scrapyd 文档中 API 示例部分\"),r(\"OutboundLink\")],1),e._v(\"强调了必须传递参数：\")]),e._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/10/1665e3b2cdcdf5b2?w=791&h=221&f=png&s=21569\",alt:\"doc\"}})]),e._v(\" \"),r(\"p\",[e._v(\"那传递的参数是以什么形式出现在代码中的呢？我们可以对其进行调试，在\"),r(\"code\",[e._v(\"args\")]),e._v(\" 的下一行（也就是 project）处打断点，并且通过 PyCharm 的 Debug 按钮启动项目，然后在浏览器访问\"),r(\"code\",[e._v(\"http://localhost:6800?project=arts\")]),e._v(\",待代码运行到断点处就可以看到 args 所获的值为\"),r(\"code\",[e._v(\"{'project': ['arts']}\")]),e._v(\"，是以字典的形式出现在代码中。\")]),e._v(\" \"),r(\"p\",[e._v(\"所以下一句代码取参数中的 project 键中第 0个位置的值，以刚才的请求作为例子，就是取到\"),r(\"code\",[e._v(\"arts\")]),e._v(\"这个名字。\")]),e._v(\" \"),r(\"p\",[e._v(\"再往下，通过 \"),r(\"code\",[e._v(\"get_spider_list\")]),e._v(\" 方法以及传递的项目名称（arts）获取爬虫的名称列表。\")]),e._v(\" \"),r(\"p\",[e._v(\"当请求参数是正确的，并且项目名称也正确，就会得到带有爬虫名称的 json 数据：\")]),e._v(\" \"),r(\"p\",[r(\"code\",[e._v('{\"node_name\": \"GannicusdeiMac\", \"status\": \"ok\", \"spiders\": [\"artspider\"]}')])]),e._v(\" \"),r(\"p\",[e._v(\"那在 \"),r(\"code\",[e._v(\"get_spider_list\")]),e._v(\" 方法中，又完成了哪些事呢？让我们通过 \"),r(\"code\",[e._v(\"Ctrl/Commond+鼠标左键\")]),e._v(\" 跟进代码：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"def get_spider_list(project, runner=None, pythonpath=None, version=''):\\n    \\\"\\\"\\\"Return the spider list from the given project, using the given runner\\\"\\\"\\\"\\n    if \\\"cache\\\" not in get_spider_list.__dict__:\\n        get_spider_list.cache = UtilsCache()\\n    try:\\n        return get_spider_list.cache[project][version]\\n    except KeyError:\\n        pass\\n    if runner is None:\\n        runner = Config().get('runner')\\n    env = os.environ.copy()\\n    env['PYTHONIOENCODING'] = 'UTF-8'\\n    env['SCRAPY_PROJECT'] = project\\n    if pythonpath:\\n        env['PYTHONPATH'] = pythonpath\\n    if version:\\n        env['SCRAPY_EGG_VERSION'] = version\\n    pargs = [sys.executable, '-m', runner, 'list']\\n    proc = Popen(pargs, stdout=PIPE, stderr=PIPE, env=env)\\n    out, err = proc.communicate()\\n    if proc.returncode:\\n        msg = err or out or ''\\n        msg = msg.decode('utf8')\\n        raise RuntimeError(msg.encode('unicode_escape') if six.PY2 else msg)\\n    # FIXME: can we reliably decode as UTF-8?\\n    # scrapy list does `print(list)`\\n    tmp = out.decode('utf-8').splitlines();\\n    try:\\n        project_cache = get_spider_list.cache[project]\\n        project_cache[version] = tmp\\n    except KeyError:\\n        project_cache = {version: tmp}\\n    get_spider_list.cache[project] = project_cache\\n    return tmp\\n\\n\")])])]),r(\"p\",[r(\"strong\",[e._v(\"代码比较长，我们挑重点来理解：\")])]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"首先，看方法的注释说明，大意是根据指定的爬虫名返回爬虫列表。\")]),e._v(\" \"),r(\"li\",[e._v(\"优先从爬虫缓存列表中读取记录，如果有则直接返回结果。\")]),e._v(\" \"),r(\"li\",[e._v(\"如无则尝试从数据库中读取。\")]),e._v(\" \"),r(\"li\",[e._v(\"最后更新项目缓存并将结果返回。\")])]),e._v(\" \"),r(\"p\",[e._v(\"官方注释原文为： \"),r(\"code\",[e._v(\"Return the spider list from the given project, using the given runner\")])]),e._v(\" \"),r(\"p\",[e._v(\"优先从爬虫缓存列表中读取记录，如果有则直接返回结果：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"return get_spider_list.cache[project][version]\\n\\n\")])])]),r(\"p\",[e._v(\"尝试从数据库中读取代码为：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"env['SCRAPY_PROJECT'] = project\\npargs = [sys.executable, '-m', runner, 'list']\\nproc = Popen(pargs, stdout=PIPE, stderr=PIPE, env=env)\\nout, err = proc.communicate()\\n\\n\")])])]),r(\"p\",[e._v(\"更新项目缓存并将结果返回代码为：\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- extra-class\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"tmp = out.decode('utf-8').splitlines();\\n    try:\\n        project_cache = get_spider_list.cache[project]\\n        project_cache[version] = tmp\\n    except KeyError:\\n        project_cache = {version: tmp}\\n    get_spider_list.cache[project] = project_cache\\n    return tmp\\n\\n\")])])]),r(\"h2\",{attrs:{id:\"关于爬虫名称列表的获取速度\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#关于爬虫名称列表的获取速度\"}},[e._v(\"#\")]),e._v(\" 关于爬虫名称列表的获取速度\")]),e._v(\" \"),r(\"p\",[e._v(\"用\"),r(\"code\",[e._v(\"get_spider_list\")]),e._v(\"方法获取爬虫名称的速度并不快，甚至可以说有点慢，所以它才会使用缓存来提升读取速度。方法中\"),r(\"code\",[e._v(\"out, err = proc.communicate()\")]),e._v(\"这句代码的运行时长约为 1.3-2.5秒，笔者通过不断的实验发现，它里面调用的其他方法中使用了\"),r(\"code\",[e._v(\"while\")]),e._v(\"以及\"),r(\"code\",[e._v(\"for 循环\")]),e._v(\"，每个循环运行的时间并不长，但是多个循环的时间累加起来就变成了1.3-2.5秒。\")]),e._v(\" \"),r(\"h2\",{attrs:{id:\"小结\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#小结\"}},[e._v(\"#\")]),e._v(\" 小结\")]),e._v(\" \"),r(\"p\",[e._v(\"本小节我们从需求与问题开始，再到代码调试的原因以及选择需要调试的几种不同类型的代码进行深入观察。在整个过程中了解到了 Scrapyd 的代码结构、代码运行流程、代码风格以及爬虫运行记录的存放处。\"),r(\"strong\",[e._v(\"由此得到一个启发：\")])]),e._v(\" \"),r(\"blockquote\",[r(\"p\",[e._v(\"对于后面的功能模块开发，我们可以从现有的代码中拿到部分资源，通过对资源的类型转换或者再次计算，得到我们需要的数据结果。\")])]),e._v(\" \"),r(\"p\",[e._v(\"比如可以通过观察\"),r(\"code\",[e._v(\"self.root\")]),e._v(\"获取爬虫运行的相关信息、使用\"),r(\"code\",[e._v(\"get_spider_list\")]),e._v(\"方法可以获得指定项目中的爬虫名列表、使用\"),r(\"code\",[e._v(\"native_stringify_dict\")]),e._v(\"方法可以获得传递的参数键值对等等。\")])])}),[],!1,null,null,null);t.default=s.exports}}]);","extractedComments":[]}