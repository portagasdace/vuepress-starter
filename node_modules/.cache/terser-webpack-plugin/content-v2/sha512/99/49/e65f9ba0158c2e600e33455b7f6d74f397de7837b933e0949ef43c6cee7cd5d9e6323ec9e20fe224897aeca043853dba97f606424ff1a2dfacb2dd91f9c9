{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[270],{624:function(e,s,t){\"use strict\";t.r(s);var a=t(42),r=Object(a.a)({},(function(){var e=this,s=e.$createElement,t=e._self._c||s;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[t(\"h1\",{attrs:{id:\"自定义-api-开发-爬虫调用情况统计\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#自定义-api-开发-爬虫调用情况统计\"}},[e._v(\"#\")]),e._v(\" 自定义 API 开发 - 爬虫调用情况统计\")]),e._v(\" \"),t(\"p\",[e._v(\"前面动手编写了\"),t(\"code\",[e._v(\"CustomResource\")]),e._v(\"，并且将其应用到原来的 HTML 视图类上。这一节我们来学习如何编写 API。\")]),e._v(\" \"),t(\"p\",[e._v(\"在之前对 API 的阅读中，我们知道 API 代码写在\"),t(\"code\",[e._v(\"scrapyd/webservice.py\")]),e._v(\"中，为了保持风格一致，我们也将代码写在此文件中。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"编写自定义-api\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#编写自定义-api\"}},[e._v(\"#\")]),e._v(\" 编写自定义 API\")]),e._v(\" \"),t(\"p\",[e._v(\"在之前的 API 源码与视图类源码的阅读中，我们知道渲染由 render 方法完成，并且可以通过\"),t(\"code\",[e._v(\"render_GET\")]),e._v(\"以及\"),t(\"code\",[e._v(\"render_POST\")]),e._v(\"来指定请求方式。\")]),e._v(\" \"),t(\"h3\",{attrs:{id:\"编写-get-类型的爬虫调用信息统计-api\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#编写-get-类型的爬虫调用信息统计-api\"}},[e._v(\"#\")]),e._v(\" 编写 GET 类型的爬虫调用信息统计 API\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"功能：爬虫调用情况\")]),e._v(\" \"),t(\"li\",[e._v(\"描述：如被调用过的爬虫、未被调用过的爬虫、被调用次数最多的爬虫名称及次数\")])]),e._v(\" \"),t(\"p\",[e._v(\"在\"),t(\"code\",[e._v(\"webservice.py\")]),e._v(\"中新建类\"),t(\"code\",[e._v(\"ScheduleList\")]),e._v(\"，它继承之前我们自己编写的视图类\"),t(\"code\",[e._v(\"CustomResource\")]),e._v(\"：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"class ScheduleList(CustomResource):\\n\\n\")])])]),t(\"p\",[e._v(\"通过对其他 API 的调试，可以知道所有运行完毕的爬虫运行信息对象以列表的形式记录在\"),t(\"code\",[e._v(\"self.root.launcher.finished\")]),e._v(\"中：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"[\\n<scrapyd.launcher.ScrapyProcessProtocol object at 0x10cf97d68>,\\n<scrapyd.launcher.ScrapyProcessProtocol object at 0x10cf546d8>,\\n<scrapyd.launcher.ScrapyProcessProtocol object at 0x10cf3d4e0>\\n]\\n\\n\")])])]),t(\"p\",[t(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/16662fee3bc4f760?w=1536&h=1002&f=gif&s=4078380\",alt:\"\"}})]),e._v(\" \"),t(\"p\",[t(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/5/16643ab60543f5ff?w=686&h=264&f=png&s=69929\",alt:\"finished object\"}})]),e._v(\" \"),t(\"p\",[e._v(\"每个对象中包含对应爬虫相关运行信息，如项目名称 project、爬虫名称 spider、启动时间 start_time、结束时间 end_time、jobid、日志路径 logfile 等。\")]),e._v(\" \"),t(\"p\",[e._v(\"根据需求，要取的数据有：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"* 所有爬虫名称\\n* 已运行完毕的爬虫名称\\n* 爬虫调用记录\\n\\n\")])])]),t(\"p\",[e._v(\"通过 A 与 B 的差值计算得出未被调用过的爬虫、通过调用记录计算爬虫调用次数并取最大次数。\")]),e._v(\" \"),t(\"p\",[e._v(\"代码逻辑：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"* 取得运行完毕的爬虫运行记录列表\\n* 获取爬虫列表\\n* 计算差值，得出已被调用与未被调用的爬虫名列表\\n* 计算爬虫调用记录中被调用次数最多的爬虫名及其次数\\n* 将结果以原 JSON 风格渲染输出\\n\\n\")])])]),t(\"p\",[e._v(\"相应代码：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v('class ScheduleList(CustomResource):\\n    def render_GET(self, request):\\n        \"\"\"爬虫调用情况\\n        如被调用过的爬虫、未被调用过的爬虫、被调用次数最多的爬虫名称及次数\\n        \"\"\"\\n        finishes = self.root.launcher.finished\\n        projects, spiders = get_ps(self)  # 项目/爬虫列表\\n        invoked_spider, un_invoked_spider, most_record = get_invokes(finishes, spiders)  # 被调用过/未被调用的爬虫\\n        return {\"node_name\": self.root.nodename, \"status\": \"ok\", \"invoked_spider\": list(invoked_spider),\\n                \"un_invoked_spider\": list(un_invoked_spider), \"most_record\": most_record}\\n\\n')])])]),t(\"p\",[e._v(\"其中通过\"),t(\"code\",[e._v(\"get_ps\")]),e._v(\"方法获取爬虫列表：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v('def get_ps(self):\\n    \"\"\"获取项目列表与爬虫列表\\n    :param self:\\n    :return: projects-项目列表， spiders-爬虫列表\\n    \"\"\"\\n    projects = list(self.root.scheduler.list_projects())\\n    spiders = get_spiders(projects)\\n    return projects, spiders\\n\\n')])])]),t(\"p\",[e._v(\"通过\"),t(\"code\",[e._v(\"get_invokes\")]),e._v(\"方法计算所需结果：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v('def get_invokes(finishes, spiders):\\n        \"\"\"获取已被调用与未被调用的爬虫名称及被调用次数最多的爬虫\\n        :param: finishes 已运行完毕的爬虫运行信息记录列表\\n        :param: spiders 所有爬虫名列表\\n        :return: invoked-被调用过的爬虫集合, un_invoked-未被调用的爬虫集合, most_record-被调用次数最多的爬虫名与次数\\n        \"\"\"\\n        invoked = set(i.spider for i in finishes)\\n        un_invoked = set(spiders).difference(invoked)\\n        invoked_record = Counter(i.spider for i in finishes)\\n        most_record = invoked_record.most_common(1)[0] if invoked_record else (\"nothing\", 0)\\n        return invoked, un_invoked, most_record\\n\\n')])])]),t(\"p\",[e._v(\"还需要通过:\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"def get_spiders(values):\\n    if not values:\\n        return []\\n    # [['tips', 'nof'], ['nop']] -> ['tips', 'nof', 'nop']\\n    value = list(reduce(lambda x, y: x+y,  map(get_spider_list, values)))  # first 2.8s\\n    return value\\n\\n\")])])]),t(\"h2\",{attrs:{id:\"自定义-api-的使用\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#自定义-api-的使用\"}},[e._v(\"#\")]),e._v(\" 自定义 API 的使用\")]),e._v(\" \"),t(\"h3\",{attrs:{id:\"配置路由\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#配置路由\"}},[e._v(\"#\")]),e._v(\" 配置路由\")]),e._v(\" \"),t(\"p\",[e._v(\"代码编写好之后，还需要在为其配置路由映射规则。打开 Scrapyd 的配置文件\"),t(\"code\",[e._v(\"default_scrapyd.conf\")]),e._v(\"，在\"),t(\"code\",[e._v(\"services\")]),e._v(\"级下添加路由，如：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"[services]\\nschedulelist.json = scrapyd.webservice.ScheduleList\\n\\n\")])])]),t(\"p\",[t(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/166630dc666d4c87?w=1074&h=424&f=gif&s=1562870\",alt:\"\"}})]),e._v(\" \"),t(\"p\",[e._v(\"保存之后重新启动 Scrapyd 服务才能生效。\")]),e._v(\" \"),t(\"h3\",{attrs:{id:\"api-的使用\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#api-的使用\"}},[e._v(\"#\")]),e._v(\" API 的使用\")]),e._v(\" \"),t(\"p\",[e._v(\"由于编写代码时选择 \"),t(\"code\",[e._v(\"render_GET\")]),e._v(\" 方法，所以在使用时与原 API 使用方式一致，如果是使用 cURL 模拟请求，则请求语句为:\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"curl: http://localhost:6800/schedulelist.json\\n\\n\")])])]),t(\"p\",[e._v(\"如果是使用 Postman 作为模拟请求工具，则：\")]),e._v(\" \"),t(\"p\",[t(\"img\",{attrs:{src:\"https://user-gold-cdn.xitu.io/2018/10/11/1666310ea7f2c5d0?w=1078&h=876&f=gif&s=786048\",alt:\"\"}})]),e._v(\" \"),t(\"p\",[e._v(\"如果使用代码（requests）发起请求，代码为：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v('import requests\\n\\nresp = requests.get(\"http://localhost:6800/schedulelist.json\")\\nprint(resp.text)\\n\\n')])])]),t(\"p\",[e._v(\"发起请求后，得到的返回结果为：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v('{\\n\"node_name\": \"node-name\",\\n\"status\": \"ok\",\\n\"invoked_spider\": [\"quinns\",\"fabias\"],\\n\"un_invoked_spider\": [\"artspider\"],\\n\"most_record\": [\"fabias\",3]\\n    \\n}\\n\\n')])])]),t(\"p\",[e._v(\"返回结果中键的含义解释：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- extra-class\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"* node_name-请求发起者\\n* status-请求状态，ok 为成功\\n* invoked_spider-被调用过的爬虫列表\\n* un_invoked_spider-未被调用过的爬虫列表\\n* most_record-被调用次数最多的爬虫名及次数\\n\\n\")])])]),t(\"h2\",{attrs:{id:\"小结\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#小结\"}},[e._v(\"#\")]),e._v(\" 小结\")]),e._v(\" \"),t(\"p\",[e._v(\"基于之前几个小节学习的知识，结合需求分析，render 选型和逻辑分析，逐步完成了自定义 API 的编写。\")])])}),[],!1,null,null,null);s.default=r.exports}}]);","extractedComments":[]}